{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the imports, classes and functions that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from collections import deque\n",
    "%matplotlib inline\n",
    "\n",
    "# A simple function to display two images that is used to show the difference between the two images\n",
    "def displayImageDiff(img1, img2, img1_string, img2_string, figsize, show_axis, tight_layout = False):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "    ax1.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title(img1_string, fontsize=18)\n",
    "    ax2.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "    ax2.set_title(img2_string, fontsize=18)\n",
    "    if show_axis is False:\n",
    "        ax1.axis('off')\n",
    "        ax2.axis('off')\n",
    "    if tight_layout is True:\n",
    "        f.tight_layout()\n",
    "\n",
    "\"\"\"\n",
    "Remove distortion from images\n",
    "It uses the calculate camera calibration matrix and distortion coefficients\n",
    "to remove distortion from an image and output the undistorted image.\n",
    "\"\"\"\n",
    "def undistort(image, show=True, read = True):\n",
    "    if read:\n",
    "        img = cv2.imread(image)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    \n",
    "    # Undistort the images\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    if show:\n",
    "        displayImageDiff(img, undist, 'Orignal Image', 'Undistorted Image', (9, 6), False)\n",
    "    else:\n",
    "        return undist\n",
    "    \n",
    "\"\"\"    \n",
    "This function transforms the undistorted image to a \"birds eye view\" of the road \n",
    "which focuses only on the lane lines and displays them in such a way that they appear\n",
    "to be relatively parallel to eachother.\n",
    "\"\"\"\n",
    "# Perform perspective transform\n",
    "def birds_eye(img, display=True, read = True):\n",
    "    # Undistort the images\n",
    "    if read:\n",
    "        undist = undistort(img, show = False)\n",
    "    else:\n",
    "        undist = undistort(img, show = False, read=False) \n",
    "    img_size = (undist.shape[1], undist.shape[0])\n",
    "    offset = 0\n",
    "    src = np.float32([[490, 482],[810, 482],\n",
    "                      [1250, 720],[40, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    \n",
    "    # Get the perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    #Warp the image\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    if display:\n",
    "        displayImageDiff(undist, warped, 'Undistorted Image', 'Undistorted and Warped Image', (9, 6), False, True)\n",
    "    else:\n",
    "        return warped, M\n",
    "    \n",
    "# Create binary thresholded images to isolate lane line pixels\n",
    "def apply_thresholds(image, show=True):\n",
    "    img, M = birds_eye(image, display = False)\n",
    "    \n",
    "    s_channel = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)[:,:,2]\n",
    "    \n",
    "    l_channel = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)[:,:,0]\n",
    "\n",
    "    b_channel = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:,:,2]   \n",
    "\n",
    "    # Threshold color channel\n",
    "    s_thresh_min = 180\n",
    "    s_thresh_max = 255\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "    \n",
    "    b_thresh_min = 155\n",
    "    b_thresh_max = 200\n",
    "    b_binary = np.zeros_like(b_channel)\n",
    "    b_binary[(b_channel >= b_thresh_min) & (b_channel <= b_thresh_max)] = 1\n",
    "    \n",
    "    l_thresh_min = 225\n",
    "    l_thresh_max = 255\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh_min) & (l_channel <= l_thresh_max)] = 1\n",
    "    \n",
    "    \n",
    "    combined_binary = np.zeros_like(s_binary)\n",
    "    combined_binary[(l_binary == 1) | (b_binary == 1)] = 1\n",
    "\n",
    "    if show == True:\n",
    "        # Plotting thresholded images\n",
    "        f, ((ax1, ax2, ax3), (ax4,ax5, ax6)) = plt.subplots(2, 3, sharey='col', sharex='row', figsize=(10,4))\n",
    "        f.tight_layout()\n",
    "        \n",
    "        ax1.set_title('Original Image', fontsize=16)\n",
    "        ax1.imshow(cv2.cvtColor(undistort(image, show=False),cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        ax2.set_title('Warped Image', fontsize=16)\n",
    "        ax2.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype('uint8'))\n",
    "        \n",
    "        ax3.set_title('s binary threshold', fontsize=16)\n",
    "        ax3.imshow(s_binary, cmap='gray')\n",
    "        \n",
    "        ax4.set_title('b binary threshold', fontsize=16)\n",
    "        ax4.imshow(b_binary, cmap='gray')\n",
    "        \n",
    "        ax5.set_title('l binary threshold', fontsize=16)\n",
    "        ax5.imshow(l_binary, cmap='gray')\n",
    "\n",
    "        ax6.set_title('Combined color thresholds', fontsize=16)\n",
    "        ax6.imshow(combined_binary, cmap='gray')\n",
    "        \n",
    "        ax1.axis('off')\n",
    "        ax2.axis('off')\n",
    "        ax3.axis('off')\n",
    "        ax4.axis('off')\n",
    "        ax5.axis('off')\n",
    "        ax6.axis('off')\n",
    "    else: \n",
    "        return combined_binary\n",
    "    \n",
    "def fill_lane(image):\n",
    "    \n",
    "    combined_binary = apply_thresholds(image, show=False)\n",
    "    \n",
    "    rightx = []\n",
    "    righty = []\n",
    "    leftx = []\n",
    "    lefty = []\n",
    "    \n",
    "    x, y = np.nonzero(np.transpose(combined_binary))\n",
    "    i = 720\n",
    "    j = 630\n",
    "    while j >= 0:\n",
    "        histogram = np.sum(combined_binary[j:i,:], axis=0)\n",
    "        left_peak = np.argmax(histogram[:640])\n",
    "        x_idx = np.where((((left_peak - 25) < x)&(x < (left_peak + 25))&((y > j) & (y < i))))\n",
    "        x_window, y_window = x[x_idx], y[x_idx]\n",
    "        if np.sum(x_window) != 0:\n",
    "            leftx.extend(x_window.tolist())\n",
    "            lefty.extend(y_window.tolist())\n",
    "\n",
    "        right_peak = np.argmax(histogram[640:]) + 640\n",
    "        x_idx = np.where((((right_peak - 25) < x)&(x < (right_peak + 25))&((y > j) & (y < i))))\n",
    "        x_window, y_window = x[x_idx], y[x_idx]\n",
    "        if np.sum(x_window) != 0:\n",
    "            rightx.extend(x_window.tolist())\n",
    "            righty.extend(y_window.tolist())\n",
    "        i -= 90\n",
    "        j -= 90\n",
    "\n",
    "    lefty = np.array(lefty).astype(np.float32)\n",
    "    leftx = np.array(leftx).astype(np.float32)\n",
    "    righty = np.array(righty).astype(np.float32)\n",
    "    rightx = np.array(rightx).astype(np.float32)\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    rightx_int = right_fit[0]*720**2 + right_fit[1]*720 + right_fit[2]\n",
    "    \n",
    "    rightx = np.append(rightx,rightx_int)\n",
    "    righty = np.append(righty, 720)\n",
    "    rightx = np.append(rightx,right_fit[0]*0**2 + right_fit[1]*0 + right_fit[2])\n",
    "    righty = np.append(righty, 0)\n",
    "    \n",
    "    leftx_int = left_fit[0]*720**2 + left_fit[1]*720 + left_fit[2]\n",
    "    leftx = np.append(leftx, leftx_int)\n",
    "    lefty = np.append(lefty, 720)\n",
    "    leftx = np.append(leftx,left_fit[0]*0**2 + left_fit[1]*0 + left_fit[2])\n",
    "    lefty = np.append(lefty, 0)\n",
    "    \n",
    "    lsort = np.argsort(lefty)\n",
    "    rsort = np.argsort(righty)\n",
    "    \n",
    "    lefty = lefty[lsort]\n",
    "    leftx = leftx[lsort]\n",
    "    \n",
    "    righty = righty[rsort]\n",
    "    rightx = rightx[rsort]\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    \n",
    "    # Measure Radius of Curvature for each lane line\n",
    "    ym_per_pix = 30./720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*np.max(lefty) + left_fit_cr[1])**2)**1.5) \\\n",
    "                                 /np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*np.max(lefty) + right_fit_cr[1])**2)**1.5) \\\n",
    "                                    /np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    \n",
    "    # Calculate the position of the vehicle\n",
    "    center = abs(640 - ((rightx_int+leftx_int)/2))\n",
    "    \n",
    "    offset = 0 \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    src = np.float32([[490, 482],[810, 482],\n",
    "                      [1250, 720],[40, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    warp_zero = np.zeros_like(combined_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    pts_left = np.array([np.flipud(np.transpose(np.vstack([left_fitx, lefty])))])\n",
    "    pts_right = np.array([np.transpose(np.vstack([right_fitx, righty]))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.polylines(color_warp, np.int_([pts]), isClosed=False, color=(0,0,255), thickness = 40)\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (combined_binary.shape[1], combined_binary.shape[0]))\n",
    "    result = cv2.addWeighted(mpimg.imread(image), 1, newwarp, 0.5, 0)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1,2, figsize=(9, 6))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(cv2.cvtColor((birds_eye(image, display=False)[0]), cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_xlim(0, 1280)\n",
    "    ax1.set_ylim(0, 720)\n",
    "    ax1.plot(left_fitx, lefty, color='green', linewidth=3)\n",
    "    ax1.plot(right_fitx, righty, color='green', linewidth=3)\n",
    "    ax1.set_title('Fit Polynomial to Lane Lines', fontsize=16)\n",
    "    ax1.invert_yaxis() # to visualize as we do the images\n",
    "    ax2.imshow(result)\n",
    "    ax2.set_title('Fill Lane Between Polynomials', fontsize=16)\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')\n",
    "    if center < 640:\n",
    "        ax2.text(200, 100, 'Vehicle is {:.2f}m left of center'.format(center*3.7/700),\n",
    "                 style='italic', color='white', fontsize=10)\n",
    "    else:\n",
    "        ax2.text(200, 100, 'Vehicle is {:.2f}m right of center'.format(center*3.7/700),\n",
    "                 style='italic', color='white', fontsize=10)\n",
    "    ax2.text(200, 175, 'Radius of curvature is {}m'.format(int((left_curverad + right_curverad)/2)),\n",
    "             style='italic', color='white', fontsize=10)\n",
    "\n",
    "\"\"\"    \n",
    "A line class for the lines to store attributes\n",
    "about the lane lines from one frame to the next.\n",
    "Inside the class I will define several functions\n",
    "which will be used to detect the pixels belonging to each lane line.\n",
    "\"\"\"\n",
    "class Line:\n",
    "    def __init__(self):\n",
    "        # Was the line found in the previous frame?\n",
    "        self.found = False\n",
    "        \n",
    "        # Remember x and y values of lanes in previous frame\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        \n",
    "        # Store recent x intercepts for averaging across frames\n",
    "        self.x_int = deque(maxlen=10)\n",
    "        self.top = deque(maxlen=10)\n",
    "        \n",
    "        # Remember previous x intercept to compare against current one\n",
    "        self.lastx_int = None\n",
    "        self.last_top = None\n",
    "        \n",
    "        # Remember radius of curvature\n",
    "        self.radius = None\n",
    "        \n",
    "        # Store recent polynomial coefficients for averaging across frames\n",
    "        self.fit0 = deque(maxlen=10)\n",
    "        self.fit1 = deque(maxlen=10)\n",
    "        self.fit2 = deque(maxlen=10)\n",
    "        self.fitx = None\n",
    "        self.pts = []\n",
    "        \n",
    "        # Count the number of frames\n",
    "        self.count = 0\n",
    "      \n",
    "    \"\"\"\n",
    "    This function is applied when the lane lines have been detected in the previous frame.\n",
    "    It uses a sliding window to search for lane pixels in close proximity (+/- 25 pixels in the x direction)\n",
    "    around the previous detected polynomial. \n",
    "    \"\"\"\n",
    "    def found_search(self, x, y):\n",
    "        xvals = []\n",
    "        yvals = []\n",
    "        if self.found == True: \n",
    "            i = 720\n",
    "            j = 630\n",
    "            while j >= 0:\n",
    "                yval = np.mean([i,j])\n",
    "                xval = (np.mean(self.fit0))*yval**2 + (np.mean(self.fit1))*yval + (np.mean(self.fit2))\n",
    "                x_idx = np.where((((xval - 25) < x)&(x < (xval + 25))&((y > j) & (y < i))))\n",
    "                x_window, y_window = x[x_idx], y[x_idx]\n",
    "                if np.sum(x_window) != 0:\n",
    "                    np.append(xvals, x_window)\n",
    "                    np.append(yvals, y_window)\n",
    "                i -= 90\n",
    "                j -= 90\n",
    "        if np.sum(xvals) == 0: \n",
    "            self.found = False # If no lane pixels were detected then perform blind search\n",
    "        return xvals, yvals, self.found\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is applied in the first few frames and/or if the lane was not successfully detected\n",
    "    in the previous frame. It uses a slinding window approach to detect peaks in a histogram of the\n",
    "    binary thresholded image. Pixels in close proimity to the detected peaks are considered to belong\n",
    "    to the lane lines.\n",
    "    \"\"\"\n",
    "    def blind_search(self, x, y, image):\n",
    "        xvals = []\n",
    "        yvals = []\n",
    "        if self.found == False: \n",
    "            i = 720\n",
    "            j = 630\n",
    "            while j >= 0:\n",
    "                histogram = np.sum(image[j:i,:], axis=0)\n",
    "                if self == Right:\n",
    "                    peak = np.argmax(histogram[640:]) + 640\n",
    "                else:\n",
    "                    peak = np.argmax(histogram[:640])\n",
    "                x_idx = np.where((((peak - 25) < x)&(x < (peak + 25))&((y > j) & (y < i))))\n",
    "                x_window, y_window = x[x_idx], y[x_idx]\n",
    "                if np.sum(x_window) != 0:\n",
    "                    xvals.extend(x_window)\n",
    "                    yvals.extend(y_window)\n",
    "                i -= 90\n",
    "                j -= 90\n",
    "        if np.sum(xvals) > 0:\n",
    "            self.found = True\n",
    "        else:\n",
    "            yvals = self.Y\n",
    "            xvals = self.X\n",
    "        return xvals, yvals, self.found\n",
    "    \n",
    "    def radius_of_curvature(self, xvals, yvals):\n",
    "        ym_per_pix = 30./720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "        fit_cr = np.polyfit(yvals*ym_per_pix, xvals*xm_per_pix, 2)\n",
    "        curverad = ((1 + (2*fit_cr[0]*np.max(yvals) + fit_cr[1])**2)**1.5) \\\n",
    "                                     /np.absolute(2*fit_cr[0])\n",
    "        return curverad\n",
    "    \n",
    "    def sort_vals(self, xvals, yvals):\n",
    "        sorted_index = np.argsort(yvals)\n",
    "        sorted_yvals = yvals[sorted_index]\n",
    "        sorted_xvals = xvals[sorted_index]\n",
    "        return sorted_xvals, sorted_yvals\n",
    "    \n",
    "    def get_intercepts(self, polynomial):\n",
    "        bottom = polynomial[0]*720**2 + polynomial[1]*720 + polynomial[2]\n",
    "        top = polynomial[0]*0**2 + polynomial[1]*0 + polynomial[2]\n",
    "        return bottom, top\n",
    "  \n",
    "\"\"\"\n",
    "This function processes a video frame by frame and outputs\n",
    "an annotated video with lane lines, radius of curvature and distance from center.\n",
    "\"\"\"\n",
    "def process_vid(image):\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    \n",
    "    # Calibrate camera and undistort image\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    # Perform perspective transform\n",
    "    offset = 0\n",
    "    src = np.float32([[490, 482],[810, 482],\n",
    "                      [1250, 720],[0, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    \n",
    "    # Generate binary thresholded images\n",
    "    b_channel = cv2.cvtColor(warped, cv2.COLOR_RGB2Lab)[:,:,2]\n",
    "    l_channel = cv2.cvtColor(warped, cv2.COLOR_RGB2LUV)[:,:,0]  \n",
    "    \n",
    "    # Set the upper and lower thresholds for the b channel\n",
    "    b_thresh_min = 145\n",
    "    b_thresh_max = 200\n",
    "    b_binary = np.zeros_like(b_channel)\n",
    "    b_binary[(b_channel >= b_thresh_min) & (b_channel <= b_thresh_max)] = 1\n",
    "    \n",
    "    # Set the upper and lower thresholds for the l channel\n",
    "    l_thresh_min = 215\n",
    "    l_thresh_max = 255\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh_min) & (l_channel <= l_thresh_max)] = 1\n",
    "\n",
    "    combined_binary = np.zeros_like(b_binary)\n",
    "    combined_binary[(l_binary == 1) | (b_binary == 1)] = 1\n",
    "    \n",
    "    # Identify all non zero pixels in the image\n",
    "    x, y = np.nonzero(np.transpose(combined_binary)) \n",
    "\n",
    "    if Left.found == True: # Search for left lane pixels around previous polynomial\n",
    "        leftx, lefty, Left.found = Left.found_search(x, y)\n",
    "        \n",
    "    if Right.found == True: # Search for right lane pixels around previous polynomial\n",
    "        rightx, righty, Right.found = Right.found_search(x, y)\n",
    "\n",
    "            \n",
    "    if Right.found == False: # Perform blind search for right lane lines\n",
    "        rightx, righty, Right.found = Right.blind_search(x, y, combined_binary)\n",
    "            \n",
    "    if Left.found == False:# Perform blind search for left lane lines\n",
    "        leftx, lefty, Left.found = Left.blind_search(x, y, combined_binary)\n",
    "\n",
    "    lefty = np.array(lefty).astype(np.float32)\n",
    "    leftx = np.array(leftx).astype(np.float32)\n",
    "    righty = np.array(righty).astype(np.float32)\n",
    "    rightx = np.array(rightx).astype(np.float32)\n",
    "            \n",
    "    # Calculate left polynomial fit based on detected pixels\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    \n",
    "    # Calculate intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    leftx_int, left_top = Left.get_intercepts(left_fit)\n",
    "    \n",
    "    # Average intercepts across n frames\n",
    "    Left.x_int.append(leftx_int)\n",
    "    Left.top.append(left_top)\n",
    "    leftx_int = np.mean(Left.x_int)\n",
    "    left_top = np.mean(Left.top)\n",
    "    Left.lastx_int = leftx_int\n",
    "    Left.last_top = left_top\n",
    "    \n",
    "    # Add averaged intercepts to current x and y vals\n",
    "    leftx = np.append(leftx, leftx_int)\n",
    "    lefty = np.append(lefty, 720)\n",
    "    leftx = np.append(leftx, left_top)\n",
    "    lefty = np.append(lefty, 0)\n",
    "    \n",
    "    # Sort detected pixels based on the yvals\n",
    "    leftx, lefty = Left.sort_vals(leftx, lefty)\n",
    "    \n",
    "    Left.X = leftx\n",
    "    Left.Y = lefty\n",
    "    \n",
    "    # Recalculate polynomial with intercepts and average across n frames\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    Left.fit0.append(left_fit[0])\n",
    "    Left.fit1.append(left_fit[1])\n",
    "    Left.fit2.append(left_fit[2])\n",
    "    left_fit = [np.mean(Left.fit0), \n",
    "                np.mean(Left.fit1), \n",
    "                np.mean(Left.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    Left.fitx = left_fitx\n",
    "    \n",
    "    # Calculate right polynomial fit based on detected pixels\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Calculate intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    rightx_int, right_top = Right.get_intercepts(right_fit)\n",
    "    \n",
    "    # Average intercepts across 5 frames\n",
    "    Right.x_int.append(rightx_int)\n",
    "    rightx_int = np.mean(Right.x_int)\n",
    "    Right.top.append(right_top)\n",
    "    right_top = np.mean(Right.top)\n",
    "    Right.lastx_int = rightx_int\n",
    "    Right.last_top = right_top\n",
    "    rightx = np.append(rightx, rightx_int)\n",
    "    righty = np.append(righty, 720)\n",
    "    rightx = np.append(rightx, right_top)\n",
    "    righty = np.append(righty, 0)\n",
    "    \n",
    "    # Sort right lane pixels\n",
    "    rightx, righty = Right.sort_vals(rightx, righty)\n",
    "    Right.X = rightx\n",
    "    Right.Y = righty\n",
    "    \n",
    "    # Recalculate polynomial with intercepts and average across n frames\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    Right.fit0.append(right_fit[0])\n",
    "    Right.fit1.append(right_fit[1])\n",
    "    Right.fit2.append(right_fit[2])\n",
    "    right_fit = [np.mean(Right.fit0), np.mean(Right.fit1), np.mean(Right.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    Right.fitx = right_fitx\n",
    "        \n",
    "    # Compute radius of curvature for each lane in meters\n",
    "    left_curverad = Left.radius_of_curvature(leftx, lefty)\n",
    "    right_curverad = Right.radius_of_curvature(rightx, righty)\n",
    "        \n",
    "    # Only print the radius of curvature every 3 frames for improved readability\n",
    "    if Left.count % 3 == 0:\n",
    "        Left.radius = left_curverad\n",
    "        Right.radius = right_curverad\n",
    "        \n",
    "    # Calculate the vehicle position relative to the center of the lane\n",
    "    position = (rightx_int+leftx_int)/2\n",
    "    distance_from_center = abs((640 - position)*3.7/700) \n",
    "                \n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    warp_zero = np.zeros_like(combined_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    pts_left = np.array([np.flipud(np.transpose(np.vstack([Left.fitx, Left.Y])))])\n",
    "    pts_right = np.array([np.transpose(np.vstack([right_fitx, Right.Y]))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.polylines(color_warp, np.int_([pts]), isClosed=False, color=(0,0,255), thickness = 40)\n",
    "    cv2.fillPoly(color_warp, np.int_(pts), (34,255,34))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0]))\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.5, 0)\n",
    "        \n",
    "    # Print distance from center on video\n",
    "    if position > 640:\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m left of center'.format(distance_from_center), (100,80),\n",
    "                 fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    else:\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m right of center'.format(distance_from_center), (100,80),\n",
    "                 fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    # Print radius of curvature on video\n",
    "    cv2.putText(result, 'Radius of Curvature {}(m)'.format(int((Left.radius+Right.radius)/2)), (120,140),\n",
    "             fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    Left.count += 1\n",
    "    return result\n",
    "\n",
    "print(\"All the functions and classes are loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Distortion Correction\n",
    "\n",
    "Distort the images so that we can get the correct information out of them because our world is in 3D but cameras are recording in 2D and some parts of the image can be distorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Get the images from the folder\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Read and correct every image\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        displayImageDiff(mpimg.imread(fname), img, 'Original Image', 'With Corners', (8,4), False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will use the `undistort()` function which uses the calculate camera calibration matrix and distortion coefficients to remove distortion from an image and output the undistorted image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply undistort function on the images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "for image in images:\n",
    "    undistort(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Perspective Transform\n",
    "\n",
    "In this steop I will apply a perspective transform. In a 2D dimension, parallel lines seem to intersect in a specific point which is not true. A perspective transform would map the current image to a new image as it would be seen from a bird's eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the warped images\n",
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    birds_eye(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Apply Binary Thresholds\n",
    "\n",
    "In this step I attempted to convert the warped image to different color spaces and create binary thresholded images which highlight only the lane lines and ignore everything else. \n",
    "I found that the following color channels and thresholds did a good job of identifying the lane lines in the provided test images:\n",
    "- The S Channel from the HLS color space, with a min threshold of 180 and a max threshold of 255, did a fairly good job of identifying both the white and yellow lane lines, but did not pick up 100% of the pixels in either one, and had a tendency to get distracted by shadows on the road.\n",
    "- The L Channel from the LUV color space, with a min threshold of 225 and a max threshold of 255, did an almost perfect job of picking up the white lane lines, but completely ignored the yellow lines.\n",
    "- The B channel from the Lab color space, with a min threshold of 155 and an upper threshold of 200, did a better job than the S channel in identifying the yellow lines, but completely ignored the white lines. \n",
    "\n",
    "I chose to create a combined binary threshold based on the three above mentioned binary thresholds, to create one combination thresholded image which does a great job of highlighting almost all of the white and yellow lane lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Apply the thresholds\n",
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    apply_thresholds(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps 4, 5 and 6: Fitting a polynomial to the lane lines, calculating vehicle position and radius of curvature:\n",
    "\n",
    "At this point I was able to use the combined binary image to isolate lane line pixels and fit a polynomial to each of the lane lines. The space in between the identified lane lines is filled in to highlight the driveable area in the lane. The position of the vehicle was measured by taking the average of the x intercepts of each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the fill lane function    \n",
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    fill_lane(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing Pipeline:\n",
    "\n",
    "I will use the Line class that was created at the beginning for the lines to store attributes about the lane lines from a frame to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Left = Line()\n",
    "Right = Line()\n",
    "video_output = 'result.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(0, 20)\n",
    "white_clip = clip1.fl_image(process_vid) \n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following is the result of the video pipeline being run on the project video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('result.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Left = Line()\n",
    "Right = Line()\n",
    "challenge_output = 'challenge_result.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "challenge_clip = clip1.fl_image(process_vid) \n",
    "challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the result of the pipeline on a harder challenge video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('challenge_result.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
